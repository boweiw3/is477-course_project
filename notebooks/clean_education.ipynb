{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/lyt/Desktop/is477-course_project-deepsick/notebooks\n",
      "BASE_DIR: /Users/lyt/Desktop/is477-course_project-deepsick\n",
      "EDU_DIR: /Users/lyt/Desktop/is477-course_project-deepsick/data/raw/education_data\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()).resolve().parent\n",
    "RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "\n",
    "EDU_DIR = RAW_DIR / \"education_data\"\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"EDU_DIR:\", EDU_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Listing Education Data Directory ===\n",
      "Found Year Folder: 15-16\n",
      "   - ccd_sea_059_1516_w_1a_011717_csv.zip\n",
      "   - ccd_sea_052_1516_w_1a_011717_csv.zip\n",
      "   - ccd_sea_052_1516_w_1a_011717_xls.zip\n",
      "   - ccd_sea_059_1516_w_1a_011717_xlsx.zip\n",
      "Found Year Folder: 17-18\n",
      "   - ccd_sea_059_1718_l_1a_083118.zip\n",
      "   - ccd_sea_052_1718_l_1a_083118.zip\n",
      "Found Year Folder: 19-20\n",
      "   - ccd_sea_052_1920_l_1a_082120.zip\n",
      "   - ccd_sea_059_1920_l_1a_082120.zip\n",
      "Found Year Folder: 21-22\n",
      "   - ccd_sea_052_2122_l_1a_071722.zip\n",
      "   - ccd_sea_059_2122_l_1a_071722.zip\n",
      "Found Year Folder: 23-24\n",
      "   - ccd_sea_052_2324_l_1a_073124.zip\n",
      "   - ccd_sea_059_2324_l_1a_073124.zip\n"
     ]
    }
   ],
   "source": [
    "# Inspect Education Data Directory Structure\n",
    "print(\"=== Listing Education Data Directory ===\")\n",
    "\n",
    "year_folders = sorted([p for p in EDU_DIR.iterdir() if p.is_dir()])\n",
    "\n",
    "for folder in year_folders:\n",
    "    print(f\"Found Year Folder: {folder.name}\")\n",
    "    files = list(folder.iterdir())\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        print(\"   (Empty folder — no files found)\")\n",
    "    else:\n",
    "        for f in files:\n",
    "            print(\"   -\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inspecting ZIP Contents ===\n",
      "Year Folder: 15-16\n",
      " ZIP File: ccd_sea_059_1516_w_1a_011717_csv.zip\n",
      "     - ccd_sea_059_1516_w_1a_011717.csv\n",
      " ZIP File: ccd_sea_052_1516_w_1a_011717_csv.zip\n",
      "     - ccd_sea_052_1516_w_1a_011717.csv\n",
      " ZIP File: ccd_sea_052_1516_w_1a_011717_xls.zip\n",
      "     - ccd_sea_052_1516_w_1a_011717.xlsx\n",
      " ZIP File: ccd_sea_059_1516_w_1a_011717_xlsx.zip\n",
      "     - ccd_sea_059_1516_w_1a_011717.xlsx\n",
      "Year Folder: 17-18\n",
      " ZIP File: ccd_sea_059_1718_l_1a_083118.zip\n",
      "     - ccd_sea_059_1718_l_1a_083118.csv\n",
      "     - ccd_sea_059_1718_l_1a_083118.sas7bdat\n",
      " ZIP File: ccd_sea_052_1718_l_1a_083118.zip\n",
      "     - ccd_sea_052_1718_l_1a_083118.csv\n",
      "     - ccd_sea_052_1718_l_1a_083118.sas7bdat\n",
      "Year Folder: 19-20\n",
      " ZIP File: ccd_sea_052_1920_l_1a_082120.zip\n",
      "     - ccd_sea_052_1920_l_1a_082120.csv\n",
      "     - ccd_sea_052_1920_l_1a_082120.sas7bdat\n",
      " ZIP File: ccd_sea_059_1920_l_1a_082120.zip\n",
      "     - ccd_sea_059_1920_l_1a_082120.csv\n",
      "     - ccd_sea_059_1920_l_1a_082120.sas7bdat\n",
      "Year Folder: 21-22\n",
      " ZIP File: ccd_sea_052_2122_l_1a_071722.zip\n",
      "     - ccd_sea_052_2122_l_1a_071722.csv\n",
      "     - ccd_sea_052_2122_l_1a_071722.sas7bdat\n",
      " ZIP File: ccd_sea_059_2122_l_1a_071722.zip\n",
      "     - ccd_sea_059_2122_l_1a_071722.csv\n",
      "     - ccd_sea_059_2122_l_1a_071722.sas7bdat\n",
      "Year Folder: 23-24\n",
      " ZIP File: ccd_sea_052_2324_l_1a_073124.zip\n",
      "     - ccd_sea_052_2324_l_1a_073124.csv\n",
      "     - ccd_sea_052_2324_l_1a_073124.sas7bdat\n",
      " ZIP File: ccd_sea_059_2324_l_1a_073124.zip\n",
      "     - ccd_sea_059_2324_l_1a_073124.csv\n",
      "     - ccd_sea_059_2324_l_1a_073124.sas7bdat\n"
     ]
    }
   ],
   "source": [
    "# Inspect ZIP Contents\n",
    "import zipfile\n",
    "\n",
    "print(\"=== Inspecting ZIP Contents ===\")\n",
    "\n",
    "for year_folder in sorted([f for f in EDU_DIR.iterdir() if f.is_dir()]):\n",
    "    print(f\"Year Folder: {year_folder.name}\")\n",
    "    \n",
    "    for zfile in year_folder.iterdir():\n",
    "        if zfile.suffix == \".zip\":\n",
    "            print(f\" ZIP File: {zfile.name}\")\n",
    "            with zipfile.ZipFile(zfile, 'r') as z:\n",
    "                for name in z.namelist():\n",
    "                    print(f\"     - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Education Data ===\n",
      "Processing 15-16 → Year = 2015\n",
      "  ✔ Reading CSV: ccd_sea_059_1516_w_1a_011717.csv\n",
      "  ✔ Reading CSV: ccd_sea_052_1516_w_1a_011717.csv\n",
      "  ⚠️ No CSV found in: ccd_sea_052_1516_w_1a_011717_xls.zip\n",
      "  ⚠️ No CSV found in: ccd_sea_059_1516_w_1a_011717_xlsx.zip\n",
      "Processing 17-18 → Year = 2017\n",
      "  ✔ Reading CSV: ccd_sea_059_1718_l_1a_083118.csv\n",
      "  ✔ Reading CSV: ccd_sea_052_1718_l_1a_083118.csv\n",
      "Processing 19-20 → Year = 2019\n",
      "  ✔ Reading CSV: ccd_sea_052_1920_l_1a_082120.csv\n",
      "  ✔ Reading CSV: ccd_sea_059_1920_l_1a_082120.csv\n",
      "Processing 21-22 → Year = 2021\n",
      "  ✔ Reading CSV: ccd_sea_052_2122_l_1a_071722.csv\n",
      "  ✔ Reading CSV: ccd_sea_059_2122_l_1a_071722.csv\n",
      "Processing 23-24 → Year = 2023\n",
      "  ✔ Reading CSV: ccd_sea_052_2324_l_1a_073124.csv\n",
      "  ✔ Reading CSV: ccd_sea_059_2324_l_1a_073124.csv\n",
      "\n",
      "=== Merge all years into one DataFrame ===\n",
      "Final Education Data Shape: (62841, 357)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SURVYEAR</th>\n",
       "      <th>FIPST</th>\n",
       "      <th>STABR</th>\n",
       "      <th>STATENAME</th>\n",
       "      <th>SEANAME</th>\n",
       "      <th>SCHSUP</th>\n",
       "      <th>SECTCH</th>\n",
       "      <th>STAFF</th>\n",
       "      <th>ELMGUI</th>\n",
       "      <th>KGTCH</th>\n",
       "      <th>...</th>\n",
       "      <th>ST</th>\n",
       "      <th>SEA_NAME</th>\n",
       "      <th>STATE_AGENCY_NO</th>\n",
       "      <th>STAFF_COUNT</th>\n",
       "      <th>TOTAL_INDICATOR</th>\n",
       "      <th>DMS_FLAG</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>STUDENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Alabama Department Of Education</td>\n",
       "      <td>1993.04</td>\n",
       "      <td>19079.63</td>\n",
       "      <td>71628.43</td>\n",
       "      <td>928.05</td>\n",
       "      <td>4535.87</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2</td>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>Alaska Department of Education and Early Devel...</td>\n",
       "      <td>1052.99</td>\n",
       "      <td>3507.40</td>\n",
       "      <td>16982.39</td>\n",
       "      <td>67.99</td>\n",
       "      <td>416.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>4</td>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>Arizona Department of Education</td>\n",
       "      <td>3790.96</td>\n",
       "      <td>14488.66</td>\n",
       "      <td>103174.6</td>\n",
       "      <td>448.17</td>\n",
       "      <td>2558.63</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>5</td>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>ARKANSAS DEPARTMENT OF EDUCATION</td>\n",
       "      <td>2926.65</td>\n",
       "      <td>14714.25</td>\n",
       "      <td>73658.2</td>\n",
       "      <td>577.88</td>\n",
       "      <td>2144.12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>California Department of Education</td>\n",
       "      <td>33873.81</td>\n",
       "      <td>84322.38</td>\n",
       "      <td>577836.1</td>\n",
       "      <td>2620.76</td>\n",
       "      <td>23014.89</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SURVYEAR  FIPST STABR   STATENAME  \\\n",
       "0  2015-2016      1    AL     ALABAMA   \n",
       "1  2015-2016      2    AK      ALASKA   \n",
       "2  2015-2016      4    AZ     ARIZONA   \n",
       "3  2015-2016      5    AR    ARKANSAS   \n",
       "4  2015-2016      6    CA  CALIFORNIA   \n",
       "\n",
       "                                             SEANAME    SCHSUP    SECTCH  \\\n",
       "0                    Alabama Department Of Education   1993.04  19079.63   \n",
       "1  Alaska Department of Education and Early Devel...   1052.99   3507.40   \n",
       "2                    Arizona Department of Education   3790.96  14488.66   \n",
       "3                   ARKANSAS DEPARTMENT OF EDUCATION   2926.65  14714.25   \n",
       "4                 California Department of Education  33873.81  84322.38   \n",
       "\n",
       "      STAFF   ELMGUI     KGTCH  ...   ST  SEA_NAME  STATE_AGENCY_NO  \\\n",
       "0  71628.43   928.05   4535.87  ...  NaN       NaN              NaN   \n",
       "1  16982.39    67.99    416.79  ...  NaN       NaN              NaN   \n",
       "2  103174.6   448.17   2558.63  ...  NaN       NaN              NaN   \n",
       "3   73658.2   577.88   2144.12  ...  NaN       NaN              NaN   \n",
       "4  577836.1  2620.76  23014.89  ...  NaN       NaN              NaN   \n",
       "\n",
       "   STAFF_COUNT  TOTAL_INDICATOR  DMS_FLAG  GRADE  RACE_ETHNICITY  SEX  \\\n",
       "0          NaN              NaN       NaN    NaN             NaN  NaN   \n",
       "1          NaN              NaN       NaN    NaN             NaN  NaN   \n",
       "2          NaN              NaN       NaN    NaN             NaN  NaN   \n",
       "3          NaN              NaN       NaN    NaN             NaN  NaN   \n",
       "4          NaN              NaN       NaN    NaN             NaN  NaN   \n",
       "\n",
       "   STUDENT_COUNT  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "\n",
       "[5 rows x 357 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract CSV Files from ZIP and Load All Education Data\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "def extract_year_from_folder(folder_name):\n",
    "    \"\"\"Convert '15-16' → 2015, '17-18' → 2017, etc.\"\"\"\n",
    "    start = int(folder_name.split('-')[0])\n",
    "    return 2000 + start if start < 50 else 1900 + start\n",
    "\n",
    "all_edu_rows = []\n",
    "\n",
    "print(\"=== Loading Education Data ===\")\n",
    "\n",
    "for year_folder in sorted([f for f in EDU_DIR.iterdir() if f.is_dir()]):\n",
    "    year_str = year_folder.name\n",
    "    year = extract_year_from_folder(year_str)\n",
    "\n",
    "    print(f\"Processing {year_folder.name} → Year = {year}\")\n",
    "\n",
    "    # Process each zip\n",
    "    for zfile in year_folder.iterdir():\n",
    "        if zfile.suffix == \".zip\":\n",
    "            with zipfile.ZipFile(zfile, \"r\") as z:\n",
    "                # Pick the CSV file inside the zip\n",
    "                csv_files = [f for f in z.namelist() if f.endswith(\".csv\")]\n",
    "                if not csv_files:\n",
    "                    print(\"  ⚠️ No CSV found in:\", zfile.name)\n",
    "                    continue\n",
    "                \n",
    "                csv_name = csv_files[0]   # always 1 CSV per zip\n",
    "                print(f\"  ✔ Reading CSV: {csv_name}\")\n",
    "\n",
    "                with z.open(csv_name) as f:\n",
    "                    df = pd.read_csv(f, low_memory=False)\n",
    "                    df[\"year\"] = year   # Add year column\n",
    "                    df[\"source_file\"] = zfile.name  # traceability\n",
    "\n",
    "                    all_edu_rows.append(df)\n",
    "\n",
    "print(\"\\n=== Merge all years into one DataFrame ===\")\n",
    "edu_df = pd.concat(all_edu_rows, ignore_index=True)\n",
    "print(\"Final Education Data Shape:\", edu_df.shape)\n",
    "\n",
    "edu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Education Data Profiling ===\n",
      "\n",
      "Shape: (62841, 357)\n",
      "\n",
      "=== First 20 Columns ===\n",
      "['SURVYEAR', 'FIPST', 'STABR', 'STATENAME', 'SEANAME', 'SCHSUP', 'SECTCH', 'STAFF', 'ELMGUI', 'KGTCH', 'LEASUP', 'PARA', 'SECGUI', 'CORSUP', 'ELMTCH', 'LIBSUP', 'SCHADM', 'STUSUP', 'GUI', 'LEAADM']\n",
      "\n",
      "=== Unique SURVYEAR values ===\n",
      "['2015-2016' nan]\n",
      "\n",
      "=== Year Column Range ===\n",
      "2015 → 2023\n",
      "\n",
      "=== Unique States (STABR) Count ===\n",
      "57\n",
      "\n",
      "Sample STABR: ['AL' 'AK' 'AZ' 'AR' 'CA' 'CO' 'CT' 'DE' 'DC' 'FL' 'GA' 'HI' 'ID' 'IL'\n",
      " 'IN']\n",
      "\n",
      "=== Missing Value Summary (Top 20) ===\n",
      "TR06M    62784\n",
      "AM10M    62784\n",
      "WH10M    62784\n",
      "BL10F    62784\n",
      "BL10M    62784\n",
      "HI10F    62784\n",
      "HI10M    62784\n",
      "AS10F    62784\n",
      "AS10M    62784\n",
      "AM10F    62784\n",
      "TR09F    62784\n",
      "AS12F    62784\n",
      "TR09M    62784\n",
      "HP09F    62784\n",
      "HP09M    62784\n",
      "WH09F    62784\n",
      "WH09M    62784\n",
      "BL09F    62784\n",
      "BL09M    62784\n",
      "HI09F    62784\n",
      "dtype: int64\n",
      "\n",
      "=== Percentage Missing (Top 20) ===\n",
      "TR06M    99.909295\n",
      "AM10M    99.909295\n",
      "WH10M    99.909295\n",
      "BL10F    99.909295\n",
      "BL10M    99.909295\n",
      "HI10F    99.909295\n",
      "HI10M    99.909295\n",
      "AS10F    99.909295\n",
      "AS10M    99.909295\n",
      "AM10F    99.909295\n",
      "TR09F    99.909295\n",
      "AS12F    99.909295\n",
      "TR09M    99.909295\n",
      "HP09F    99.909295\n",
      "HP09M    99.909295\n",
      "WH09F    99.909295\n",
      "WH09M    99.909295\n",
      "BL09F    99.909295\n",
      "BL09M    99.909295\n",
      "HI09F    99.909295\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Education Data Profiling\n",
    "print(\"=== Education Data Profiling ===\\n\")\n",
    "\n",
    "print(\"Shape:\", edu_df.shape)\n",
    "\n",
    "# Preview column names\n",
    "print(\"\\n=== First 20 Columns ===\")\n",
    "print(list(edu_df.columns[:20]))\n",
    "\n",
    "# Check survey years (string)\n",
    "print(\"\\n=== Unique SURVYEAR values ===\")\n",
    "print(edu_df['SURVYEAR'].unique())\n",
    "\n",
    "# Check derived numeric year\n",
    "print(\"\\n=== Year Column Range ===\")\n",
    "print(edu_df['year'].min(), \"→\", edu_df['year'].max())\n",
    "\n",
    "# Check states\n",
    "print(\"\\n=== Unique States (STABR) Count ===\")\n",
    "print(edu_df['STABR'].nunique())\n",
    "print(\"\\nSample STABR:\", edu_df['STABR'].unique()[:15])\n",
    "\n",
    "# Missing values summary\n",
    "missing = edu_df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\n=== Missing Value Summary (Top 20) ===\")\n",
    "print(missing.head(20))\n",
    "\n",
    "print(\"\\n=== Percentage Missing (Top 20) ===\")\n",
    "print((missing / len(edu_df) * 100).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Data Overview\n",
    "\n",
    "The education dataset contains **62,841 rows** and **357 columns**, covering multiple years of state-level K–12 education statistics from the CCD SEA files.\n",
    "\n",
    "**Key fields include:**\n",
    "\n",
    "- `SURVYEAR`: survey year label (most values are `\"2015-2016\"`)\n",
    "- `year`: derived numeric year (ranges from **2015–2023**)\n",
    "- `STABR`: 57 unique state abbreviations (includes states + D.C. + territories)\n",
    "- `STATENAME`: full state name\n",
    "- 300+ numerical indicators on staffing, enrollment, expenditures, and administration\n",
    "\n",
    "### Missingness Summary\n",
    "\n",
    "A large number of detailed demographic and finance variables have **extremely high missingness** (often > 99%).  \n",
    "Most of these fields represent detailed subcategories only available for some states or years.\n",
    "\n",
    "Common examples with heavy missingness include:\n",
    "\n",
    "- `TR06M`, `AM10M`, `WH10M`, `BL10F`, `BL10M`, and many other subgroup variables\n",
    "- Many columns exceed **99% missing** and do not contribute meaningful analytic value\n",
    "\n",
    "In contrast, core variables such as `STABR`, `STATENAME`, and major staffing/enrollment totals have low or no missingness.\n",
    "\n",
    "### State Coverage\n",
    "\n",
    "The dataset includes **57 unique STABR values**, indicating:\n",
    "\n",
    "- 50 U.S. states  \n",
    "- Washington, D.C.  \n",
    "- Additional territories (e.g., Puerto Rico, Guam, Virgin Islands)\n",
    "\n",
    "Only states + D.C. will be used to match with crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking Column-Level Missing Percentages ===\n",
      "\n",
      "=== Top 30 Columns with Highest Missing (%) ===\n",
      "TR06M    99.909295\n",
      "AM10M    99.909295\n",
      "WH10M    99.909295\n",
      "BL10F    99.909295\n",
      "BL10M    99.909295\n",
      "HI10F    99.909295\n",
      "HI10M    99.909295\n",
      "AS10F    99.909295\n",
      "AS10M    99.909295\n",
      "AM10F    99.909295\n",
      "TR09F    99.909295\n",
      "AS12F    99.909295\n",
      "TR09M    99.909295\n",
      "HP09F    99.909295\n",
      "HP09M    99.909295\n",
      "WH09F    99.909295\n",
      "WH09M    99.909295\n",
      "BL09F    99.909295\n",
      "BL09M    99.909295\n",
      "HI09F    99.909295\n",
      "WH10F    99.909295\n",
      "HP10M    99.909295\n",
      "HP10F    99.909295\n",
      "TR10M    99.909295\n",
      "AM12F    99.909295\n",
      "AM12M    99.909295\n",
      "TR11F    99.909295\n",
      "TR11M    99.909295\n",
      "HP11F    99.909295\n",
      "HP11M    99.909295\n",
      "dtype: float64\n",
      "\n",
      "=== Columns With < 5% Missing (Likely Usable) ===\n",
      "['DMS_FLAG', 'TOTAL_INDICATOR', 'SEA_NAME', 'STATE_AGENCY_NO', 'ST', 'SCHOOL_YEAR', 'source_file', 'STATENAME', 'year', 'FIPST']\n",
      "\n",
      "Total usable columns (<5% missing): 10\n",
      "\n",
      "=== Columns With > 95% Missing (Likely to Drop) ===\n",
      "['TR06M', 'AM10M', 'WH10M', 'BL10F', 'BL10M', 'HI10F', 'HI10M', 'AS10F', 'AS10M', 'AM10F', 'TR09F', 'AS12F', 'TR09M', 'HP09F', 'HP09M', 'WH09F', 'WH09M', 'BL09F', 'BL09M', 'HI09F', 'WH10F', 'HP10M', 'HP10F', 'TR10M', 'AM12F', 'AM12M', 'TR11F', 'TR11M', 'HP11F', 'HP11M', 'WH11F', 'WH11M', 'BL11F', 'BL11M', 'HI11F', 'HI11M', 'AS11F', 'AS11M', 'AM11F', 'AM11M', 'TR10F', 'HI09M', 'AS09F', 'AS09M', 'WH07F', 'BL07F', 'BL07M', 'HI07F', 'HI07M', 'AS07F', 'AS07M', 'AM07F', 'AM07M', 'TR06F', 'IG11', 'HP06F', 'HP06M', 'WH06F', 'WH06M', 'BL06F', 'BL06M', 'HI06F', 'WH07M', 'HP07M', 'AM09F', 'HP07F', 'AM09M', 'TR08F', 'TR08M', 'HP08F', 'HP08M', 'WH08F', 'WH08M', 'BL08F', 'BL08M', 'HI08F', 'HI08M', 'AS08F', 'AS08M', 'AM08F', 'AM08M', 'TR07F', 'TR07M', 'AS12M', 'HI12M', 'IG10', 'AMALM', 'BL', 'HIALF', 'HIALM', 'HI', 'ASALF', 'ASALM', 'AS', 'AMALF', 'AM', 'HI12F', 'TRAEF', 'TRAEM', 'HPAEF', 'HPAEM', 'WHAEF', 'WHAEM', 'BLAEF', 'BLAEM', 'BLALM', 'BLALF', 'WH', 'WHALM', 'IG08', 'IG07', 'IG06', 'IG05', 'IG04', 'IG03', 'IG02', 'IG01', 'IKG', 'IPK', 'TRALF', 'TRALM', 'TR', 'HPALF', 'HPALM', 'HP', 'WHALF', 'HIAEF', 'HIAEM', 'ASAEF', 'HP13M', 'WH13M', 'BL13F', 'BL13M', 'HI13F', 'HI13M', 'AS13F', 'AS13M', 'AM13F', 'AM13M', 'TR12F', 'TR12M', 'HP12F', 'HP12M', 'WH12F', 'WH12M', 'BL12F', 'BL12M', 'WH13F', 'HP13F', 'ASAEM', 'TR13M', 'AMAEF', 'AMAEM', 'TRUGF', 'TRUGM', 'HPUGF', 'HPUGM', 'WHUGF', 'WHUGM', 'BLUGF', 'BLUGM', 'HIUGF', 'HIUGM', 'ASUGF', 'ASUGM', 'AMUGF', 'AMUGM', 'TR13F', 'HI06M', 'AS06F', 'AS06M', 'G03', 'G11', 'G10', 'G09', 'G08', 'G07', 'G06', 'G05', 'G04', 'G02', 'AM06F', 'G01', 'KG', 'PK', 'IG12', 'IG13', 'ITOTGUI', 'ITOTTCH', 'IUGTCH', 'G12', 'G13', 'UG', 'AE', 'AMKGM', 'TRPKF', 'TRPKM', 'HPPKF', 'HPPKM', 'WHPKF', 'WHPKM', 'BLPKF', 'BLPKM', 'HIPKF', 'HIPKM', 'ASPKF', 'ASPKM', 'AMPKF', 'AMPKM', 'MEMBER', 'TOTAL', 'IPKTCH', 'IOTHSUP', 'ILIBSPE', 'LIBSPE', 'GUI', 'STUSUP', 'SCHADM', 'LIBSUP', 'ELMTCH', 'CORSUP', 'SECGUI', 'PARA', 'LEASUP', 'KGTCH', 'ELMGUI', 'IUG', 'SECTCH', 'SCHSUP', 'IAE', 'ITOTAL', 'IMEMBER', 'LEAADM', 'OTHSUP', 'ILEAADM', 'PKTCH', 'IGUI', 'ISTUSUP', 'ISCHADM', 'ILIBSUP', 'IELMTCH', 'ICORSUP', 'ISECGUI', 'IPARA', 'ILEASUP', 'IKGTCH', 'IELMGUI', 'ISTAFF', 'ISECTCH', 'ISCHSUP', 'TOTGUI', 'TOTTCH', 'UGTCH', 'AMKGF', 'ASKGM', 'ASKGF', 'WH04F', 'BL04F', 'BL04M', 'HI04F', 'HI04M', 'AS04F', 'AS04M', 'AM04F', 'AM04M', 'TR03F', 'TR03M', 'HP03F', 'HP03M', 'WH03F', 'WH03M', 'BL03F', 'BL03M', 'HI03F', 'WH04M', 'HP04M', 'AS03F', 'HP04F', 'AM06M', 'TR05F', 'TR05M', 'HP05F', 'HP05M', 'WH05F', 'WH05M', 'BL05F', 'BL05M', 'HI05F', 'HI05M', 'AS05F', 'AS05M', 'AM05F', 'AM05M', 'TR04F', 'TR04M', 'HI03M', 'AS03M', 'HIKGM', 'WH01F', 'BL01F', 'BL01M', 'HI01F', 'HI01M', 'AS01F', 'AS01M', 'AM01F', 'AM01M', 'TRKGF', 'TRKGM', 'HPKGF', 'HPKGM', 'WHKGF', 'WHKGM', 'BLKGF', 'BLKGM', 'HIKGF', 'WH01M', 'HP01M', 'AM03F', 'HP01F', 'AM03M', 'TR02F', 'TR02M', 'HP02F', 'HP02M', 'WH02F', 'WH02M', 'BL02F', 'BL02M', 'HI02F', 'HI02M', 'AS02F', 'AS02M', 'AM02F', 'AM02M', 'TR01F', 'TR01M', 'IG09', 'SURVYEAR', 'SEANAME', 'STABR']\n",
      "\n",
      "Total columns >95% missing: 341\n"
     ]
    }
   ],
   "source": [
    "# === Step E3: Identify Usable Columns in Education Data ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Checking Column-Level Missing Percentages ===\")\n",
    "\n",
    "# Calculate % missing per column\n",
    "edu_missing_pct = edu_df.isna().mean() * 100\n",
    "\n",
    "# Sort descending\n",
    "edu_missing_pct_sorted = edu_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Show top 30 columns with highest missing\n",
    "print(\"\\n=== Top 30 Columns with Highest Missing (%) ===\")\n",
    "print(edu_missing_pct_sorted.head(30))\n",
    "\n",
    "# Show columns with < 5% missing (likely usable)\n",
    "usable_cols = edu_missing_pct_sorted[edu_missing_pct_sorted < 5].index.tolist()\n",
    "\n",
    "print(\"\\n=== Columns With < 5% Missing (Likely Usable) ===\")\n",
    "print(usable_cols)\n",
    "\n",
    "print(f\"\\nTotal usable columns (<5% missing): {len(usable_cols)}\")\n",
    "\n",
    "# Show columns with > 95% missing (likely discard)\n",
    "discard_cols = edu_missing_pct_sorted[edu_missing_pct_sorted > 95].index.tolist()\n",
    "\n",
    "print(\"\\n=== Columns With > 95% Missing (Likely to Drop) ===\")\n",
    "print(discard_cols)\n",
    "print(f\"\\nTotal columns >95% missing: {len(discard_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Data Profiling Summary\n",
    "\n",
    "- The merged NCES CCD dataset contains **62,841 rows and 357 columns**.\n",
    "- The majority of columns represent detailed race/grade/sex staff breakdowns.  \n",
    "  However, **341 out of 357 columns (95%) have more than 95% missing values**, and thus are not suitable for analysis.\n",
    "- Only a small subset of columns—including core state identifiers and aggregated staffing counts—have complete or near-complete coverage.\n",
    "- The key usable identifier columns include:  \n",
    "  `SURVYEAR`, `STABR`, `STATENAME`\n",
    "- Many racial/grade-specific variables (e.g., `TR06M`, `AM10M`, `WH10F`, etc.) show **>99% missing** and will be removed during cleaning.\n",
    "- The dataset spans survey years **2015–2023**, matching the project’s crime-data timeline.\n",
    "- Unique states (STABR) ≈ **57**, consistent with US states + DC + territories.\n",
    "\n",
    "Overall, the profiling indicates that the education dataset is highly sparse in detailed breakdown fields, and the cleaning step will focus on retaining only the core educational metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Data Cleaning Plan (Updated After Profiling)\n",
    "\n",
    "1. **Filter to valid U.S. states only**  \n",
    "   - The dataset includes 57 unique `STABR` values, which contain U.S. states, D.C., and additional territories (e.g., PR, VI, GU).  \n",
    "   - Only the 50 states + D.C. will be kept to align with the crime dataset.\n",
    "\n",
    "2. **Drop columns with extremely high missingness (>95%)**  \n",
    "   - Profiling shows that **341 of 357 columns** exceed 95% missing, mostly detailed race × grade × gender staff counts.  \n",
    "   - These variables are not consistently reported and will be removed.\n",
    "\n",
    "3. **Retain only core, consistently available education indicators**  \n",
    "   - Keep robust, aggregated variables such as:  \n",
    "     - `STAFF` (total staff)  \n",
    "     - `SECTCH` (secondary teachers)  \n",
    "     - `ELMTCH` (elementary teachers)  \n",
    "     - `SCHSUP` (school support staff)  \n",
    "     - `STUSUP` (student support)  \n",
    "     - `LEAADM` / `SCHADM` (administrative staff)  \n",
    "     - Enrollment-related variables (e.g., `MEMBER`, `TOTAL`, `IMEMBER`)  \n",
    "   - These fields are available across nearly all states and years.\n",
    "\n",
    "4. **Ensure that the numeric `year` column is used for merging**  \n",
    "   - The original `SURVYEAR` field contains strings like `\"2015-2016\"`.  \n",
    "   - Profiling confirmed that the derived `year` column (2015–2023) is accurate and will be used for merging with crime data.\n",
    "\n",
    "5. **Remove rows with missing or invalid state identifiers**  \n",
    "   - Although most `STABR` values are valid, any rows with missing/invalid state codes will be dropped.\n",
    "\n",
    "6. **Standardize column names and formats**  \n",
    "   - Convert to lowercase for consistency.  \n",
    "   - Rename key identifiers:  \n",
    "     - `STABR` → `state`  \n",
    "     - `STATENAME` → `state_name`\n",
    "\n",
    "7. **Create additional derived indicators (optional but useful)**  \n",
    "   - After cleaning, generate interpretable metrics:  \n",
    "     - *Student–teacher ratio*  \n",
    "     - *Teacher per 1,000 students*  \n",
    "     - *Staff per 1,000 students*  \n",
    "   - These will support clearer comparisons between states and years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name sample: Index(['survyear', 'fipst', 'stabr', 'statename', 'seaname', 'schsup',\n",
      "       'sectch', 'staff', 'elmgui', 'kgtch', 'leasup', 'para', 'secgui',\n",
      "       'corsup', 'elmtch'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 2 — Standardize column names: lowercase & replace spaces/hyphens\n",
    "edu_clean = edu_df.copy()\n",
    "edu_clean.columns = (\n",
    "    edu_clean.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"-\", \"_\")\n",
    ")\n",
    "\n",
    "print(\"Column name sample:\", edu_clean.columns[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with >95% missing: 341\n",
      "Example of columns to drop: ['survyear', 'stabr', 'seaname', 'schsup', 'sectch', 'elmgui', 'kgtch', 'leasup', 'para', 'secgui', 'corsup', 'elmtch', 'libsup', 'schadm', 'stusup']\n",
      "\n",
      "Shape after dropping high-missing columns: (62841, 16)\n"
     ]
    }
   ],
   "source": [
    "# Step 2 — Drop columns with >95% missing\n",
    "\n",
    "missing_ratio = edu_clean.isna().mean()\n",
    "\n",
    "drop_cols = missing_ratio[missing_ratio > 0.95].index.tolist()\n",
    "\n",
    "print(\"Number of columns with >95% missing:\", len(drop_cols))\n",
    "print(\"Example of columns to drop:\", drop_cols[:15])\n",
    "\n",
    "edu_clean = edu_clean.drop(columns=drop_cols)\n",
    "\n",
    "print(\"\\nShape after dropping high-missing columns:\", edu_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fipst</th>\n",
       "      <th>statename</th>\n",
       "      <th>staff</th>\n",
       "      <th>year</th>\n",
       "      <th>source_file</th>\n",
       "      <th>school_year</th>\n",
       "      <th>st</th>\n",
       "      <th>sea_name</th>\n",
       "      <th>state_agency_no</th>\n",
       "      <th>staff_count</th>\n",
       "      <th>total_indicator</th>\n",
       "      <th>dms_flag</th>\n",
       "      <th>grade</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>sex</th>\n",
       "      <th>student_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>71628.43</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>16982.39</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>103174.6</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>73658.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>577836.1</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fipst   statename     staff  year                           source_file  \\\n",
       "0      1     ALABAMA  71628.43  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "1      2      ALASKA  16982.39  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "2      4     ARIZONA  103174.6  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "3      5    ARKANSAS   73658.2  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "4      6  CALIFORNIA  577836.1  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "\n",
       "  school_year   st sea_name  state_agency_no  staff_count total_indicator  \\\n",
       "0         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "1         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "2         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "3         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "4         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "\n",
       "  dms_flag grade race_ethnicity  sex  student_count  \n",
       "0      NaN   NaN            NaN  NaN            NaN  \n",
       "1      NaN   NaN            NaN  NaN            NaN  \n",
       "2      NaN   NaN            NaN  NaN            NaN  \n",
       "3      NaN   NaN            NaN  NaN            NaN  \n",
       "4      NaN   NaN            NaN  NaN            NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3 — Standardize column names\n",
    "\n",
    "rename_map = {\n",
    "    \"FIPST\": \"state_fips\",\n",
    "    \"STABR\": \"state_abbr\",\n",
    "    \"STATENAME\": \"state\",\n",
    "}\n",
    "\n",
    "edu_clean = edu_clean.rename(columns=rename_map)\n",
    "\n",
    "edu_clean.columns = edu_clean.columns.str.lower()\n",
    "\n",
    "edu_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique years before filtering: [2015, 2017, 2019, 2021, 2023]\n",
      "Shape after year filter: (62841, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fipst</th>\n",
       "      <th>statename</th>\n",
       "      <th>staff</th>\n",
       "      <th>year</th>\n",
       "      <th>source_file</th>\n",
       "      <th>school_year</th>\n",
       "      <th>st</th>\n",
       "      <th>sea_name</th>\n",
       "      <th>state_agency_no</th>\n",
       "      <th>staff_count</th>\n",
       "      <th>total_indicator</th>\n",
       "      <th>dms_flag</th>\n",
       "      <th>grade</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>sex</th>\n",
       "      <th>student_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>71628.43</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>16982.39</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>103174.6</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>73658.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>577836.1</td>\n",
       "      <td>2015</td>\n",
       "      <td>ccd_sea_059_1516_w_1a_011717_csv.zip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fipst   statename     staff  year                           source_file  \\\n",
       "0      1     ALABAMA  71628.43  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "1      2      ALASKA  16982.39  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "2      4     ARIZONA  103174.6  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "3      5    ARKANSAS   73658.2  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "4      6  CALIFORNIA  577836.1  2015  ccd_sea_059_1516_w_1a_011717_csv.zip   \n",
       "\n",
       "  school_year   st sea_name  state_agency_no  staff_count total_indicator  \\\n",
       "0         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "1         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "2         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "3         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "4         NaN  NaN      NaN              NaN          NaN             NaN   \n",
       "\n",
       "  dms_flag grade race_ethnicity  sex  student_count  \n",
       "0      NaN   NaN            NaN  NaN            NaN  \n",
       "1      NaN   NaN            NaN  NaN            NaN  \n",
       "2      NaN   NaN            NaN  NaN            NaN  \n",
       "3      NaN   NaN            NaN  NaN            NaN  \n",
       "4      NaN   NaN            NaN  NaN            NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 — Clean year column & filter valid years\n",
    "\n",
    "# Ensure year is numeric\n",
    "edu_clean[\"year\"] = pd.to_numeric(edu_clean[\"year\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Unique years before filtering:\", sorted(edu_clean[\"year\"].dropna().unique()))\n",
    "\n",
    "# Keep only 2015–2023\n",
    "edu_clean = edu_clean[(edu_clean[\"year\"] >= 2015) & (edu_clean[\"year\"] <= 2023)]\n",
    "\n",
    "print(\"Shape after year filter:\", edu_clean.shape)\n",
    "\n",
    "edu_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after selecting core columns: (62841, 4)\n",
      "Columns now: ['fipst', 'statename', 'staff', 'year']\n",
      "Rows before dropping NA in key fields: 62841\n",
      "Rows after  dropping NA in key fields: 5786\n",
      "Removed: 57055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_fips</th>\n",
       "      <th>state</th>\n",
       "      <th>edu_staff_total</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>71628.43</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>16982.39</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>103174.6</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>73658.2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>577836.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_fips       state edu_staff_total  year\n",
       "0           1     ALABAMA        71628.43  2015\n",
       "1           2      ALASKA        16982.39  2015\n",
       "2           4     ARIZONA        103174.6  2015\n",
       "3           5    ARKANSAS         73658.2  2015\n",
       "4           6  CALIFORNIA        577836.1  2015"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5 — keep only useful columns & rename\n",
    "\n",
    "keep_cols = [\"fipst\", \"statename\", \"staff\", \"year\"]\n",
    "edu_clean = edu_clean[keep_cols].copy()\n",
    "\n",
    "print(\"Shape after selecting core columns:\", edu_clean.shape)\n",
    "print(\"Columns now:\", edu_clean.columns.tolist())\n",
    "\n",
    "edu_clean = edu_clean.rename(\n",
    "    columns={\n",
    "        \"statename\": \"state\",\n",
    "        \"staff\": \"edu_staff_total\",\n",
    "        \"fipst\": \"state_fips\"\n",
    "    }\n",
    ")\n",
    "\n",
    "before = edu_clean.shape[0]\n",
    "edu_clean = edu_clean.dropna(subset=[\"state\", \"year\", \"edu_staff_total\"])\n",
    "after = edu_clean.shape[0]\n",
    "\n",
    "print(f\"Rows before dropping NA in key fields: {before}\")\n",
    "print(f\"Rows after  dropping NA in key fields: {after}\")\n",
    "print(f\"Removed: {before - after}\")\n",
    "\n",
    "edu_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()).resolve().parent\n",
    "\n",
    "clean_dir = BASE_DIR / \"data\" / \"cleaned\"\n",
    "clean_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = clean_dir / \"education_cleaned.csv\"\n",
    "edu_clean.to_csv(output_file, index=False)\n",
    "\n",
    "# print(\"Saved cleaned education data to:\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
